# %% Imports and library configurations
from cuqi.distribution import DistributionGallery, Gaussian, JointDistribution
from cuqi.testproblem import Poisson1D
from cuqi.problem import BayesianProblem
import cuqi
import inspect
import numpy as np
import matplotlib.pyplot as plt
from cuqi.sampler import MH, CWMH, ULA, MALA, NUTS
import time
import scipy.stats as sps
from scipy.stats import gaussian_kde
import pandas as pd
import cProfile, pstats, io
from pstats import SortKey
from prettytable import PrettyTable
from IPython.display import Image, display
import math
import warnings

# %% General MCMC sampling function
def MCMC_sampling(target, method, adapted, scale, Ns, Nb, x0=None, seed=None):

    """
    Perform MCMC sampling given a target distribution, method, and parameters.
    
    Parameters:
    target  : cuqi.distribution.Distribution object
    method  : cuqi.sampler.Sampler class (MH, CWMH, ULA, etc.)
    adapted : boolean, if the MH sampler is adapted or not
    scale   : float or array, scaling factor for the sampler
    Ns      : int, number of samples
    Nb      : int, number of burn-ins
    x0      : initial state, either an array or a CUQI distribution
    seed    : int, random seed

    Returns:
    x       : cuqi.samples.Samples, samples generated by the sampler
    pr      : cProfile.Profile, profiling object to analyze the performance
    """
    if hasattr(x0, '__module__') and x0.__module__.startswith("cuqi.distribution"):
        x0 = x0.sample().to_numpy()

    pr = cProfile.Profile()
    pr.enable()
    try:
        np.random.seed(seed)
        if method == NUTS: 
            # sampler = method(target = target, x0 = x0)
            sampler = method(target = target, x0 = x0)
            # \x = xamsampler.warmup(Nb)
            # sampler.sample(Ns)
            # x = sampler.get_samples()\\\\\
        
        # elif method == MALA:
        #     sampler = cuqi.experimental.mcmc.MALA(target)
        #     sampler.warmup(Nb)
        #     sampler.sample(Ns)
        #     x = sampler.get_samples()

        else:
            sampler = method(target = target, scale = scale, x0 = x0)
            # Edit here 
        if adapted:
            x = sampler.sample_adapt(Ns,Nb)
        else: 
            x = sampler.sample(Ns,Nb)

    finally:
        pr.disable()
    return x, pr

# %% Precompute samples function
def precompute_samples(target, scale, Ns , Nb , x0=None, seed=12, selected_methods = ["MH",  "CWMH" ,"ULA", "MALA", "NUTS"]):

    """
    Precompute samples for various MCMC methods and return the results.
    
    Parameters:
    target : cuqi.distribution.Distribution object
    scale  : float or array, scaling factors for the samplers
    Ns     : int or array, number of samples for each sampler
    Nb     : int or array, number of burn-ins for each sampler
    x0     : initial state, either an array or a CUQI distribution
    seed   : int, random seed
    selected_methods: list of strings, selected sampling methods (e.g., )
     

    Returns:
    samples : dict, containing samples for each MCMC method
    pr      : dict, containing profiling objects for each MCMC method
    scale   : array, adjusted scaling factors
    Ns      : array, adjusted number of samples
    Nb      : array, adjusted number of burn-ins
    """
    np.random.seed(seed)
       
    
    if isinstance(scale, float):
        scale = np.full(len(selected_methods), scale)
    if isinstance(Ns, int):
        Ns = np.full(len(selected_methods), int(Ns))
    if isinstance(Nb, int):
        Nb = np.full(len(selected_methods), int(Nb))
    
    samples = {}
    pr = {}
    
    # Dictionary to map method names to their corresponding parameters and functions
    method_mapping = {
        'MH': (MH, False),
        'MH_adapted': (MH, True),
        'CWMH': (CWMH, False),
        'CWMH_adapted': (CWMH, True),
        'ULA': (ULA, False),
        'ULA_adapted': (ULA, True),
        'MALA': (MALA, False),
        'MALA_adapted': (MALA, True),
        'NUTS': (NUTS, False),
        'NUTS_adapted': (NUTS, True)

    }

    # Loop over selected methods and compute samples
    for idx, method in enumerate(selected_methods):
        if method in method_mapping:
            mcmc_method, adapted = method_mapping[method]
            samples[method], pr[method] = MCMC_sampling(target, mcmc_method, adapted, scale[idx], Ns[idx], Nb[idx], x0, seed)
    
    return samples, pr, scale, Ns, Nb



# %% Function to count function calls in profiling results
def count_function(pr, string):
    """
    Count occurrences of a specific function call in profiling results.
    
    Parameters:
    pr     : dict, containing profiling objects for each MCMC method
    string : str, function name to count in the profiling results

    Returns:
    counter : dict, containing counts of the specified function calls for each method
    """
    counter = {}

    for method in pr.keys():
        s = io.StringIO()
        ps = pstats.Stats(pr[method], stream=s).sort_stats(SortKey.PCALLS)
        ps.print_stats()
        lines = s.getvalue().split('\n')
        
        if any(string in line for line in lines):
            idx = [string in line for line in lines].index(True)
            counter[method] = int(lines[idx].split()[0])
        else:
            counter[method] = 0  # If the function was not found, set the count to 0

    return counter


# %% Compute ESS for all sampling methods
def compute_ESS(samples, dim):
    """Compute effective sample size (ESS) for the selected sampling methods."""
    ess_values = {}
    ess = {}
    mean = {}
    for method in samples.keys():
        ess_values[method] = samples[method].compute_ess()
        mean[method] = np.mean(ess_values[method])
        if dim > 2:
            ess[method] = {
                'max': np.max(ess_values[method]),
                'min': np.min(ess_values[method])
                # 'mean': np.mean(ess_values[method])
            }
        else:
            ess = ess_values 
    
    return ess, mean


# %% Compute acceptance rate for all sampling methods
def compute_AR(samples):
    """Compute acceptance rate (AR) for the selected sampling methods."""
    ar = {}

    for method in samples.keys():

        if method == 'NUTS' or 'CWMH' or 'NUTS_adapted' or 'CWMH_adapted':
            ar[method] = len(np.unique(samples[method].samples[0])) / len(samples[method].samples[0])
        else:
            ar[method] = samples[method].acc_rate
    
    return ar


# %% Utility function to safely access array elements
def safe_access(value, index=None):
    """Safely access the value at the specified index or the scalar value and format integers."""
    if isinstance(value, (list, np.ndarray)):
        accessed_value = value[index]
    else:
        accessed_value = value

    # If the value is an integer or a whole number, return it as an int, otherwise round to 3 decimals
    if isinstance(accessed_value, (int, np.integer)) or accessed_value.is_integer():
        return int(accessed_value)
    else:
        return round(accessed_value, 3)

#%%

def compute_Rhat(samples, data, dim):
    """
    Compute Rhat statistic for convergence diagnostics across multiple chains.
    
    Parameters:
    samples : dict, containing samples for each MCMC method
    data    : list of dicts, containing samples from different chains for each method

    Returns:
    rhat : dict, containing Rhat values for each sampling method
    """
    rhat = {}
    rhat_values = {}
    mean_rhat ={}

    for method in samples.keys():
        rhat_values[method] = samples[method].compute_rhat([item[method] for item in data])
        mean_rhat[method] = np.mean(rhat_values[method]) #havent tested it yet
        if dim >=3: 
            rhat[method] = {
                'max': np.max(rhat_values[method]),
                'min': np.min(rhat_values[method]),

            }
        else:
            rhat = rhat_values

    return rhat

# %%

def create_comparison( target , scale, Ns, Nb , dim = 2, x0 = None, seed =None, chains = 2, selected_criteria= ["ESS", "AR", "LogPDF", "Gradient","Rhat"], selected_methods =["MH", "CWMH", "ULA", "MALA", "NUTS"]):

    """
    Create a table comparing various sampling methods with ESS values.
    
    Parameters:
    target : cuqi.distribution.Distribution object
    scale  : float or array, scaling factors for the samplers
    Ns     : int or array, number of samples for each sampler
    Nb     : int or array, number of burn-ins for each sampler
    x0     : initial state, either an array or a CUQI distribution
    seed   : int, random seed
    chains : int, number of MCMC chains for Rhat calculation
    selected_criteria : list of strings, selected criteria for comparison (e.g., ["ESS", "AR"])
    selected_methods:
    
    Returns:
    df   : pandas.DataFrame, comparison table
    plot : matplotlib figure, plot of the samples
    """

    # Run precomputation
    samples, pr,  scale, Ns, Nb = precompute_samples(target, scale, Ns, Nb, x0, seed, selected_methods)
    df_dict ={}
    for method in selected_methods:
        df_dict[method] ={}

    for idx, method in enumerate(selected_methods):
        df_dict[method]["samples"] = int(Ns[idx])
        df_dict[method]["burnins"] = int(Nb[idx])
        if method == "NUTS" or method == "NUTS_adapted":
            df_dict[method]["scale"] = "-"
        else: df_dict[method]["scale"] = scale[idx]

    if "ESS" in selected_criteria:

        ess, mean = compute_ESS(samples, dim)
        # mean = compute_meanESS(samples)  
        if dim ==1: 
            for method in selected_methods:
                df_dict[method]["ESS"] = safe_access(ess[method].item())
        elif dim == 2:
            for method in selected_methods: 
                df_dict[method]["ESS(v0)"] = safe_access(ess[method], 0)
                df_dict[method]["ESS(v1)"] = safe_access(ess[method], 1)
        else: 
            for method in selected_methods: 
                df_dict[method]["ESS(max)"] = safe_access(ess[method]['max'])
                df_dict[method]["ESS(min)"] = safe_access(ess[method]['min'])
                df_dict[method]["ESS(mean)"] = safe_access(mean[method])
    if "AR" in selected_criteria:
        ar = compute_AR(samples)
        for method in selected_methods:
            df_dict[method]["AR"] = safe_access(ar[method])

    if "LogPDF" in selected_criteria:
        logpdf = count_function(pr, "logpdf")
        for method in selected_methods:
            df_dict[method]["LogPDF"] = int(logpdf[method]) #make them nice
            
    
    
    if "Gradient" in selected_criteria:
        gradient = count_function(pr, "_gradient")
        for method in selected_methods:
            df_dict[method]["Gradient"] = int(gradient[method]) #make them nice
            # df_dict['Gradient'] = [int(x) if pd.notnull(x) else '-' for x in df_dict['Gradient']]

    if "Rhat" in selected_criteria:
        if hasattr(target,'prior'):
            x0 = target.prior
        if hasattr(x0, '__module__') and x0.__module__.startswith("cuqi.distribution"):
            data = []
            for i in range(chains - 1):
                chain_samples, _, _, _, _ = precompute_samples(target, scale, Ns, Nb, x0, i, selected_methods)
                data.append(chain_samples)
            rhat = compute_Rhat(samples, data, dim)
            if dim == 1:
                for method in selected_methods: 
                    df_dict[method]["Rhat"] = rhat[method]
            elif dim == 2:
                for method in selected_methods: 
                    df_dict[method]["Rhat(v0)"] = safe_access(rhat[method], 0)
                    df_dict[method]["Rhat(v1)"] = safe_access(rhat[method], 1)
            else:
                for method in selected_methods:
                    df_dict[method]["Rhat(max)"] = safe_access(rhat[method]['max'])
                    df_dict[method]["Rhat(min)"] = safe_access(rhat[method]['min'])
    if "ESS" in selected_criteria and "LogPDF" in selected_criteria:
        for method in selected_methods:
            df_dict[method]["LogPDF/ESS"] = safe_access(logpdf[method]/mean[method])
    
    if "ESS" in selected_criteria and "Gradient" in selected_criteria:
        for method in selected_methods:
            df_dict[method]["Gradient/ESS"] = safe_access(gradient[method]/mean[method])

    df = pd.DataFrame(df_dict)
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", FutureWarning)
        df.loc['samples'] = df.loc['samples'].apply(lambda x: f"{x:.0f}")
        df.loc['burnins'] = df.loc['burnins'].apply(lambda x: f"{x:.0f}")
        if "LogPDF" in selected_criteria:
            df.loc['LogPDF'] = df.loc['LogPDF'].apply(lambda x: f"{x:.0f}")
        if "Gradient" in selected_criteria:
            df.loc['Gradient'] = df.loc['Gradient'].apply(lambda x: f"{x:.0f}")

    if dim !=2:
        return df
    else: 
        # Generate sampling plot
        plot = plot_sampling(samples, target, selected_methods)   

        # Display the DataFrame without the index
        return df, plot

#%%
#plotting function 
def plot2d(val, x1_min, x1_max, x2_min, x2_max, N2=201, **kwargs):
    # plot
    pixelwidth_x = (x1_max-x1_min)/(N2-1)
    pixelwidth_y = (x2_max-x2_min)/(N2-1)

    hp_x = 0.5*pixelwidth_x
    hp_y = 0.5*pixelwidth_y

    extent = (x1_min-hp_x, x1_max+hp_x, x2_min-hp_y, x2_max+hp_y)

    plt.imshow(val, origin='lower', extent=extent, **kwargs)
    plt.colorbar()


def plot_pdf_2D(distb, x1_min, x1_max, x2_min, x2_max, N2=201, **kwargs):
    N2 = 201
    ls1 = np.linspace(x1_min, x1_max, N2)
    ls2 = np.linspace(x2_min, x2_max, N2)
    grid1, grid2 = np.meshgrid(ls1, ls2)
    distb_pdf = np.zeros((N2,N2))
    for ii in range(N2):
        for jj in range(N2):
            distb_pdf[ii,jj] = np.exp(distb.logd(np.array([grid1[ii,jj], grid2[ii,jj]]))) 
    plot2d(distb_pdf, x1_min, x1_max, x2_min, x2_max, N2, **kwargs)

def plot_pdf_1D(distb, min, max, **kwargs):
    grid = np.linspace(min, max, 1000)
    y = [distb.pdf(grid_point) for grid_point in grid]
    plt.plot(grid, y, **kwargs)

# %% Plot the sampling results
def plot_sampling(samples, target, selected_methods):
    """Plot the sampling results for visual comparison."""
    # Determine the number of selected methods
    num_methods = len(selected_methods)
    
    # Create a figure with subplots based on the number of selected methods
    num_cols = 3  # We can fit up to 3 plots per row
    num_rows = (num_methods + num_cols - 1) // num_cols  # Calculate required rows
    fig, axs = plt.subplots(num_rows, num_cols, figsize=(6*num_cols, 6*num_rows))  # Adjust the figure size as needed
    
    # If there's only one row, axs will not be a 2D array, so we need to handle that case
    if num_rows == 1:
        axs = np.expand_dims(axs, axis=0)
    
    # Flatten axs to iterate easily if the number of plots is less than the grid size
    axs = axs.flatten()

    # Loop through each selected method and plot the corresponding samples
    for i, method in enumerate(selected_methods):
        k = max(4, np.max(np.abs(samples[method].samples)))
        # k = max(10, np.max(np.abs(samples[method].samples)))
        
        # Set the current axes to the correct subplot
        plt.sca(axs[i])
        
        # Plot the target distribution first
        plot_pdf_2D(target, -k, k, -k, k)
        
        # Plot the MCMC samples on top of the target distribution
        samples[method].plot_pair(ax=axs[i])
        
        axs[i].set_title(f'{method.replace("_", " ").title()} Samples')
    
    # Hide any unused subplots if fewer methods are selected
    for j in range(i + 1, len(axs)):
        fig.delaxes(axs[j])
    
    # Adjust layout to prevent overlap
    plt.tight_layout()
    plt.close(fig)

    return fig, axs



#%%
def show_plot(fig):
    fig.savefig("output_plot.png")
    display(Image(filename="output_plot.png"))