{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will compare different samplig methods for the target `donut_target`, specifically the ess method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the needed libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuqi.distribution import DistributionGallery, Gaussian, JointDistribution\n",
    "from cuqi.testproblem import Poisson1D\n",
    "from cuqi.problem import BayesianProblem\n",
    "import cuqi\n",
    "import inspect\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cuqi.sampler import MH, CWMH, ULA, MALA, NUTS\n",
    "import time\n",
    "import scipy.stats as sps\n",
    "from scipy.stats import gaussian_kde\n",
    "import pandas as pd\n",
    "import cProfile, pstats, io\n",
    "from pstats import SortKey\n",
    "import TableAutomization as TA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The donut distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The donut distribution \n",
    "target_donut = DistributionGallery(\"donut\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mu = np.array([0, 0])\n",
    "true_sigma = np.array([1,1])\n",
    "y = cuqi.distribution.Gaussian(mean=true_mu, cov=true_sigma**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1200 / 1200\n",
      "\n",
      "Average acceptance rate: 0.888 \n",
      "\n",
      "Sample 1200 / 1200\n",
      "\n",
      "Average acceptance rate: 0.489 MCMC scale: 0.3721849738247371 \n",
      "\n",
      "Sample 1200 / 1200\n",
      "Sample 1200 / 1200\n",
      "Sample 1200 / 1200\n",
      "Sample 1200 / 1200\n",
      "\n",
      "Average acceptance rate: 0.888 \n",
      "\n",
      "Sample 1200 / 1200\n",
      "\n",
      "Average acceptance rate: 0.489 MCMC scale: 0.3721849738247371 \n",
      "\n",
      "Sample 1200 / 1200\n",
      "Sample 1200 / 1200\n",
      "Sample 1200 / 1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df, (fig, axs) = TA.create_comparison(target_donut, 0.05, 1000,200, x0 = y, seed = 12,chains=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Method  No. of Samples  No. of Burn-ins  Scaling Factor  ESS (v0)  ESS (v1)    AR  Rhat (v0)  Rhat (v1)  LogPDF  Gradient\n",
      "       MH_fixed            1000              200            0.05     1.372     2.192 0.888      1.757      1.369  1200.0       0.0\n",
      "     MH_adapted            1000              200            0.05     1.840     3.246 0.489      1.384      1.167  1200.0       0.0\n",
      "            ULA            1000              200            0.05     2.226    17.857 1.000      1.319      0.999  1200.0    1200.0\n",
      "           MALA            1000              200            0.05     8.514     7.197 0.623      1.046      1.044  1200.0    1200.0\n",
      "           NUTS            1000              200            0.05   354.011   303.138 0.827      1.012      1.012 37547.0   37547.0\n"
     ]
    }
   ],
   "source": [
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"output_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all of the sampling methods we choose 5:\n",
    "- MH with fixed samlpler\n",
    "- MH with adapted sampler\n",
    "- ULA\n",
    "- MALA \n",
    "- NUTS\n",
    "\n",
    "We create a general sampling function, that given certain inputs will compute the according MCMC sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prettytable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprettytable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PrettyTable\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create a PrettyTable object\u001b[39;00m\n\u001b[0;32m      4\u001b[0m table \u001b[38;5;241m=\u001b[39m PrettyTable()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'prettytable'"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "# Create a PrettyTable object\n",
    "table = PrettyTable()\n",
    "\n",
    "# Add columns to the table\n",
    "table.field_names = df.columns.tolist()\n",
    "for row in df.itertuples(index=False):\n",
    "    table.add_row(row)\n",
    "\n",
    "# Print the table\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
